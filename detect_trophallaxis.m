function [BBoxes, Scores] = detect_trophallaxis(net,video,outpath,roiRect,leftEdges,upEdges,l,l_net)
% DETECT_TROPHALLAXIS - detects trophallaxis in a video using a trained dnn
% Each frame of the video is cropped into small tiles (given by the
% parameters generated by 'get_roi_for_trophallaxis_detection'). 
% The tiles are classified by a dnn.
%
% Syntax:  [BBoxes, Scores] = detect_trophallaxis(net,video,outpath,roiRect,leftEdges,upEdges,l,l_net)
%
% Inputs:
%   net      - a DAGNetwork object containing a trained dnn for trophallaxis detection
%   video    - a VideoReader object of a video in which to detect trophallaxis
%   outpath  - a string of the directory in which the output will be saved
%   roiRect  - a 4-element numeric vector indicating the size and position of
%              the ROI in which to search for trophallaxes, in the form
%              [xmin ymin width height]. Generated by the function
%              'get_roi_for_trophallaxis_detection'.
%   leftEdges - matrix containing all 'xmin's of the tiling squares. Generated 
%              by the function 'get_roi_for_trophallaxis_detection'.
%   upEdges  - matrix containing all 'ymin's of the tiling squares. Generated 
%              by the function 'get_roi_for_trophallaxis_detection'.
%   l        - (optional) integer indicating the length of the tile square edge (default 175)
%   l_net    - (optional) integer indicating the edge length of the image
%              that is accepted by the classification network. (default 244)
%
% Outputs:
%   BBoxes   - a 1-by-m cell array of bounding boxes indicating the posititions
%             of detected trophallaxis, where m is the number of frames in the video.
%             If trophallaxis was detected in a frame, the corresponding cell will
%             contain an n-by-4 matrix representing the bounding boxes of the
%             detections in that frame. (n is the number of detections in that frame.) 
%             Each bounding box is a 4-element row vector in the form [xmin ymin
%             width height]. Cells of frames with no detected trophallaxis
%             will be empty.
%   Scores   - a 1-by-m cell array of scores of detected trophallaxis, where
%             m is the number of frames in the video. If trophallaxis was
%             detected in a frame, the corresponding cell will contail an
%             n-by-1 numerical vector of the scores of the detections in
%             that frame. n is the number of detections in that frame. Each
%             score is a number between 0.25-1, indicating the network's
%             output for a detection for the class "trophallaxis", where 1
%             is the highest match. (In the case of 4 categories, scores below 
%             0.25 will not be classified as trophallaxis). Cells of frames 
%             with no detected trophallaxis will be empty.
%
%
% Subfunctions: detect_trophallaxis_in_frame, splitFrame, createBoxes_around_Detections
%


%------------- BEGIN CODE --------------

if nargin < 9
    l = 175;
    l_net = 224;
end

n_frames = video.Duration*video.FrameRate;

BBoxes = {};
Scores = {};

reversemsg = '';
for f = 1:n_frames

    % display progress
    msg = sprintf('frame %i out of %i \n', f, n_frames);
    fprintf([reversemsg, msg]);
    reversemsg = repmat(sprintf('\b'), 1, length(msg));
    
    Inest = imcrop(rgb2gray(readFrame(video)),roiRect);
    
    [mergedBoxes, mergedScores] = detect_trophallaxis_in_frame(net, Inest, leftEdges, upEdges, l, l_net);
    
    BBoxes{f} = mergedBoxes;
    Scores{f} = mergedScores;
    
end

save(fullfile(outpath,'detection_data.mat'), 'BBoxes','Scores')

end


%%
function [mergedBoxes, mergedScores] = detect_trophallaxis_in_frame(net, cropped_I, leftEdges, upEdges, l, l_net)

% cut the frame to small tiles
smallPics = splitFrame(cropped_I, leftEdges, upEdges, l, l_net);

% classify the tiles
[YPred,scores] = classify(net,smallPics,'MiniBatchSize',128);
detections = YPred=='trophallaxis';

% get bounding boxes and scores of detections
[mergedBoxes, ~, mergedScores] = createBoxes_around_Detections(leftEdges, upEdges, l, detections, scores(detections,4), @mean);

end


%%
function smallPics = splitFrame(I, leftEdges, upEdges, l, ln)

% cut frame to tiles
smallPics = zeros(ln,ln,1,numel(leftEdges));
for j=1:numel(leftEdges)
    croppedI = imcrop(I,[leftEdges(j),upEdges(j),l,l]);
    croppedI_resize = imresize(croppedI, [ln ln]);
    smallPics(:,:,:,j) = croppedI_resize;
end
smallPics = uint8(smallPics);
smallPics = repmat(smallPics,1,1,3,1);


end

%% 
function [mergedBoxes, num_detections, mergedScores] = createBoxes_around_Detections(leftEdges, upEdges, l, detections, scores, scoreType)


num_all_detections = sum(detections);

bboxes = [leftEdges(detections), upEdges(detections), l*ones(num_all_detections,1), l*ones(num_all_detections,1)];
xmin = bboxes(:,1);
ymin = bboxes(:,2);
xmax = xmin + bboxes(:,3) - 1;
ymax = ymin + bboxes(:,4) - 1;

% find overlapping detections
Intersections = rectint(bboxes,bboxes);
Intersections = Intersections-diag(diag(Intersections));
g = graph(Intersections);
componentIndices = conncomp(g);

% Merge overlapping boxes based on the minimum and maximum coordinates.
xmin = accumarray(componentIndices', xmin, [], @min);
ymin = accumarray(componentIndices', ymin, [], @min);
xmax = accumarray(componentIndices', xmax, [], @max);
ymax = accumarray(componentIndices', ymax, [], @max);

% calculate scores for merged boxes
mergedScores = accumarray(componentIndices',scores,[],scoreType);

mergedBoxes = [xmin, ymin, xmax-xmin+1, ymax-ymin+1];
num_detections = size(mergedBoxes,1);

end

%------------- END OF CODE --------------